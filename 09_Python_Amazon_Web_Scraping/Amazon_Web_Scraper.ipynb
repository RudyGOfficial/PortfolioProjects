{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82121d64",
   "metadata": {},
   "source": [
    "# Amazon Web Scraper Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f72901",
   "metadata": {},
   "source": [
    "As a Data Analyst, I am tasked to build an Amazon Web Scraper Python script that extracts HTML from a web page, retrieves product datapoints, and puts the data into a CSV file & DataFrame.\n",
    "\n",
    "Run the Kernel for cells 1-4. Then try out cells 5 & 6 individually to see how the script scrapes data from one url vs multiple urls.\n",
    "\n",
    "You can change the 'seconds' argument to have the scraper repeatedly scrape the url(s) until the Kernel is interrupted.\n",
    "\n",
    "Review results by opening the CSV or viewing the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ac92c",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b94351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c7d14",
   "metadata": {},
   "source": [
    "#### Hard-Code Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be989470",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = os.getcwd() + \"\\\\\"\n",
    "csv_name = \"AmazonProducts.csv\"\n",
    "\n",
    "default_url = [\"https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/\"]\n",
    "\n",
    "# Retrieved from \"https://httpbin.org/get\" to set user-agent\n",
    "page_headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\"}\n",
    "\n",
    "table_headers = ['Title','Price','Date','Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214dfe5",
   "metadata": {},
   "source": [
    "#### Write Amazon Scraper Class to Encapsulate Web Scraping Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0208d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonScraper():\n",
    "    # Assign hard-coded variables to instance variables\n",
    "    def __init__(self, directory_path, csv_name, default_url, page_headers, table_headers):\n",
    "        self.directory_path = directory_path\n",
    "        self.csv_name = csv_name\n",
    "        self.url_list = default_url\n",
    "        self.current_url = default_url[0]\n",
    "        self.page_headers = page_headers\n",
    "        self.table_headers = table_headers\n",
    "        self.table_data = None\n",
    "        self.page_response = None\n",
    "        self.soup = None\n",
    "        self.df = None\n",
    "    \n",
    "    # Run an HTTP Request to retrieve web page HTML\n",
    "    def HTTPRequest(self):\n",
    "        self.page_response = requests.get(self.current_url)\n",
    "        return self.page_response.status_code\n",
    "    \n",
    "    # Make soup with the HTML received from the HTML request\n",
    "    def MakeSoup(self):\n",
    "        self.soup = BeautifulSoup(self.page_response.content, \"html.parser\")\n",
    "        return self.soup\n",
    "    \n",
    "    # Retrieve specific datapoints from the soup, clean, & store in table data list\n",
    "    def RetrieveData(self):\n",
    "        title = self.soup.find(id='productTitle').get_text().strip()\n",
    "        \n",
    "        whole = self.soup.find(class_=\"a-price-whole\").get_text().replace('.','').strip()\n",
    "        fraction = self.soup.find(class_=\"a-price-fraction\").get_text().strip()\n",
    "        price = f\"{whole}.{fraction}\"\n",
    "        \n",
    "        date = datetime.date.today()\n",
    "        time = datetime.datetime.now().time()\n",
    "        \n",
    "        self.table_data = [title,price,date,time]\n",
    "        \n",
    "        return self.table_data\n",
    "    \n",
    "    # Create a CSV using the table headers if a CSV with the stored file name does not exist\n",
    "    def CreateCSV(self):\n",
    "        if os.path.exists(self.csv_name):\n",
    "            return False\n",
    "\n",
    "        with open(self.csv_name, 'w', newline='', encoding='UTF8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(self.table_headers)\n",
    "        return True\n",
    "    \n",
    "    # Drop a CSV that has the stored file name if it does exist\n",
    "    def DropCSV(self):\n",
    "        if os.path.exists(self.csv_name):\n",
    "            os.remove(self.csv_name)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    # Append table data to a CSV file (create CSV if non-existant)\n",
    "    def AddDataToCSV(self):\n",
    "        if not os.path.exists(self.csv_name):\n",
    "            self.CreateCSV()\n",
    "        \n",
    "        with open(self.csv_name, 'a+', newline = '', encoding='UTF8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(self.table_data)\n",
    "        return True\n",
    "    \n",
    "    # Build a DataFrame with the specified CSV in the directory path\n",
    "    def BuildDataFrame(self):\n",
    "        self.df = pd.read_csv(self.directory_path + self.csv_name)\n",
    "        return self.df\n",
    "    \n",
    "    # Run all class methods with customizations for scraping & csv/df processing\n",
    "    def AutoPageScraper(self, custom_urls=False, drop_csv=False, seconds=-1):\n",
    "        if custom_urls:\n",
    "            self.url_list = custom_urls\n",
    "        else:\n",
    "            self.url_list = default_url\n",
    "        if drop_csv:\n",
    "            self.DropCSV()\n",
    "        \n",
    "        while True:\n",
    "            for url in self.url_list:\n",
    "                self.current_url = url\n",
    "                self.HTTPRequest()\n",
    "                self.MakeSoup()\n",
    "                self.RetrieveData()\n",
    "                self.AddDataToCSV()\n",
    "                self.BuildDataFrame()\n",
    "            if seconds > 0:\n",
    "                time.sleep(seconds)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d2a00b",
   "metadata": {},
   "source": [
    "#### Initialize AmazonScraper Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6638fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_scraper = AmazonScraper(directory_path, csv_name, default_url, page_headers, table_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd007e",
   "metadata": {},
   "source": [
    "#### Run AutoPageScraper Function with Default URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945710b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Funny Got Data MIS Data Systems Business Analy...</td>\n",
       "      <td>16.99</td>\n",
       "      <td>2024-05-04</td>\n",
       "      <td>00:27:20.121257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Price        Date  \\\n",
       "0  Funny Got Data MIS Data Systems Business Analy...  16.99  2024-05-04   \n",
       "\n",
       "              Time  \n",
       "0  00:27:20.121257  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_scraper.AutoPageScraper(custom_urls=False, drop_csv=True, seconds=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41cfb72",
   "metadata": {},
   "source": [
    "#### Run AutoPageScraper Function with Custom URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11bbd6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Converse Men's Chuck Taylor All Star Canvas Hi...</td>\n",
       "      <td>83.36</td>\n",
       "      <td>2024-05-04</td>\n",
       "      <td>00:27:21.484753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nintendo Switch™ with Neon Blue and Neon Red J...</td>\n",
       "      <td>199.99</td>\n",
       "      <td>2024-05-04</td>\n",
       "      <td>00:27:22.937506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super Mario Odyssey - US Version</td>\n",
       "      <td>38.66</td>\n",
       "      <td>2024-05-04</td>\n",
       "      <td>00:27:24.296561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Price        Date  \\\n",
       "0  Converse Men's Chuck Taylor All Star Canvas Hi...   83.36  2024-05-04   \n",
       "1  Nintendo Switch™ with Neon Blue and Neon Red J...  199.99  2024-05-04   \n",
       "2                   Super Mario Odyssey - US Version   38.66  2024-05-04   \n",
       "\n",
       "              Time  \n",
       "0  00:27:21.484753  \n",
       "1  00:27:22.937506  \n",
       "2  00:27:24.296561  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_urls = ['https://www.amazon.com/Converse-Unisex-Chuck-Taylor-Shield/dp/B01GDH9DII/',\n",
    "           'https://www.amazon.com/Nintendo-SwitchTM-Neon-Blue-Joy%E2%80%91ConTM-Switch/dp/B0BFJWCYTL/',\n",
    "           'https://www.amazon.com/Super-Mario-Odyssey-Nintendo-Switch/dp/B01MY7GHKJ/']\n",
    "amazon_scraper.AutoPageScraper(custom_urls, drop_csv=True, seconds=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
